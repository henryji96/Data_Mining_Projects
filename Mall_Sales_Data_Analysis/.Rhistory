#another 25 of c1 / another 25 of c2
test <- c(setdiff(1:100, train))
#construct train/test set
df.train <- data.frame(class = as.factor(class[train]),  # 1 or 0
x2 = x2[train],
x1 = x1[train])
df.test <- data.frame(class = as.factor(class[test]),
x2 = x2[test],
x1 = x1[test])
#svm with linear kernal
svm.linear <- svm(class~.,
data=df.train,
kernel="linear",
cost=10)
plot(svm.linear, df.train)
svm.test.pred <- predict(svm.linear, df.test)
table(class[test], svm.test.pred)
svm.train.pred <- predict(svm.linear, df.train)
table(class[train], svm.train.pred)
F1_Score(class[train], svm.train.pred)
F1_Score(class[train], svm.test.pred)
#svm with polynomial kernal
svm.polynomial <- svm(class~.,
data=df.train,
kernel="polynomial",
cost=10)
plot(svm.polynomial,df.train)
svm.test.pred <- predict(svm.polynomial, df.test)
table(class[-train], svm.test.pred)
svm.train.pred <- predict(svm.polynomial, df.train)
table(class[train], svm.train.pred)
F1_Score(class[train], svm.train.pred)
F1_Score(class[train], svm.test.pred)
#svm with radical kernal
svm.radial <- svm(class~.,
data=df.train,
kernel="radial",
cost=10, gamma=1)
plot(svm.radial, df.train)
svm.test.pred <- predict(svm.radial, df.test)
table(class[test], svm.test.pred)
svm.train.pred <- predict(svm.radial, df.train)
table(class[train], svm.train.pred)
F1_Score(class[train], svm.train.pred)
F1_Score(class[train], svm.test.pred)
#a
set.seed(2)
x <- matrix(rnorm(20 * 3 * 50, mean = 0, sd = 0.001), ncol = 50)
x[1:20, 2] <- 1
x[21:40, 1] <- 2
x[21:40, 2] <- 2
x[41:60, 1] <- 1
true.labels <- c(rep(1,20), rep(2,20), rep(3,20))
#b
pr.out <- prcomp(x)
plot(pr.out$x[, 1:2], col = 1:3, xlab = "Z1", ylab = "Z2", pch = 19)
#c
km.out <- kmeans(x, 3, nstart = 20)
table(true.labels, km.out$cluster)
#d
help(kmeans)
km.out <- kmeans(x, 2, nstart = 20)
table(true.labels, km.out$cluster)
#e
km.out <- kmeans(x, 4, nstart = 20)
table(true.labels, km.out$cluster)
#f
km.out <- kmeans(pr.out$x[, 1:2], 3, nstart = 20)
table(true.labels, km.out$cluster)
#g
km.out <- kmeans(scale(x), 3, nstart = 20)
table(true.labels, km.out$cluster)
#Generate a simulated two-class data set
library(e1071)
library(MLmetrics)
set.seed(2)
x1 <- rnorm(100)
x2 <- 6*x1^2 + 3 + rnorm(100)
sample.c1 <- sample(100, 50)
x2[sample.c1] <-x2[sample.c1] + 2
x2[-sample.c1] <-x2[-sample.c1] - 2
# Plot data
plot(x1[sample.c1], x2[sample.c1], col="blue",
ylim=c(-2, 20), xlab="X1", ylab="X2")
points(x1[-sample.c1], x2[-sample.c1], col="red")
# class
class <- rep(0, 100) #class.c2
class[sample.c1] <- 1
#25 of c1 / 25 of c2
train <- c(sample(sample.c1, 25), sample(setdiff(1:100, sample.c1), 25))
#another 25 of c1 / another 25 of c2
test <- c(setdiff(1:100, train))
#construct train/test set
df.train <- data.frame(class = as.factor(class[train]),  # 1 or 0
x2 = x2[train],
x1 = x1[train])
df.test <- data.frame(class = as.factor(class[test]),
x2 = x2[test],
x1 = x1[test])
#svm with linear kernal
svm.linear <- svm(class~.,
data=df.train,
kernel="linear",
cost=10)
plot(svm.linear, df.train)
svm.test.pred <- predict(svm.linear, df.test)
table(class[test], svm.test.pred)
svm.train.pred <- predict(svm.linear, df.train)
table(class[train], svm.train.pred)
F1_Score(class[train], svm.train.pred)
F1_Score(class[train], svm.test.pred)
#svm with polynomial kernal
svm.polynomial <- svm(class~.,
data=df.train,
kernel="polynomial",
cost=10)
plot(svm.polynomial,df.train)
svm.test.pred <- predict(svm.polynomial, df.test)
table(class[-train], svm.test.pred)
p <- seq(0,1,0.01)
Gini <- 2 * p * (1 -p)
ClassError <- 1 - pmax(p,1-p)
Entropy <- - (p * log(p) + (1 - p) * log(1 - p))
matplot(p, cbind(Gini,ClassError,Entropy), col = c("red", "brown", "blue"))
library(tree)
OjTree <- tree(Purchase ~ ., data = trainData)
summary(OjTree)
library(ISLR)
set.seed(0001)
train <- sample(1:nrow(OJ), 800)
trainData <- OJ[train, ]
testData <- OJ[-train, ]
library(tree)
OjTree <- tree(Purchase ~ ., data = trainData)
summary(OjTree)
train
trainData
OjTree
plot(OjTree)
text(OjTree,pretty = 0)
TreePredict <- predict(OjTree, testData, type = "class")
table(TreePredict, testData$Purchase)
TestError <- (12+49)/270
TestError
CrossV <- cv.tree(OjTree , FUN = prune.misclass)
CrossV
opar <- par(no.readonly=T)
par(pch=17)
plot(CrossV$size, CrossV$dev, type = "b", xlab = "Tree size", ylab = "classification error rate",col = 'gold')
par(opar)
CrossV$size
CrossV$dev
OjPrun <- prune.misclass(OjTree, best = 2)
plot(OjPrun)
text(OjPrun, pretty = 0)
summary(OjTree)
summary(OjPrun)
summary(OjTree)
summary(OjPrun)
Prunped <- predict(OjPrun, testData, type = "class")
summary(Prunped)
table(Prunped, testData$Purchase)
TestError <- (30+40)/ 270
TestError
plot(NA, NA, type = "n", xlim = c(-4, 2), ylim = c(-1, 5), asp = 1, xlab = "X1", ylab = "X2")
symbols(c(-1), c(2), circles = c(2), add = TRUE, inches = FALSE)
text(c(-1), c(2), "< 4")
text(c(-4), c(2), "> 4")
opar <- par(no.readonly=T)
par(pch=19)
x1 <- c(0, -1, 2, 3)
x2 <- c(0, 1, 2, 8)
plot(x1, x2, col = c("blue", "red", "blue", "blue"), asp = 1, xlab = "X1", ylab = "X2")
symbols(c(-1), c(2), circles = c(2), add = TRUE, inches = FALSE)
plot(NA, NA, type = "n", xlim = c(-4, 2), ylim = c(-1, 5), asp = 1, xlab = "X1", ylab = "X2")
symbols(c(-1), c(2), circles = c(2), add = TRUE, inches = FALSE)
text(c(-1), c(2), "< 4")
text(c(-4), c(2), "> 4")
opar <- par(no.readonly=T)
par(pch=19)
x1 <- c(0, -1, 2, 3)
x2 <- c(0, 1, 2, 8)
plot(x1, x2, col = c("blue", "red", "blue", "blue"), asp = 1, xlab = "X1", ylab = "X2")
symbols(c(-1), c(2), circles = c(2), add = TRUE, inches = FALSE)
#a
set.seed(10)
x1 <- runif(500) - 0.5
x2 <- runif(500) - 0.5
y <- 1 * (x1^2 - x2^2 > 0)
help(runif)
#b
plot(x1, x2, xlab = "X1", ylab = "X2",
col = y+1, pch =y+2)
logit.reg <- glm(y ~ x1 + x2, family = binomial)
summary(logit.reg)
#d
data <- data.frame(x1 = x1, x2 = x2, y = y)
proba <- predict(logit.reg, data, type = "response")
preds <- ifelse(proba > 0.51, 1, 0)
pred.pos <- data[preds == 1, ]
pred.neg <- data[preds == 0, ]
plot(pred.pos$x1, pred.pos$x2,
col = 'black', pch = 2,
xlab = "X1", ylab = "X2")
points(pred.neg$x1, pred.neg$x2, col = 'red', pch = 3)
#c
logit.reg <- glm(y ~ x1 + x2, family = binomial)
summary(logit.reg)
#d
data <- data.frame(x1 = x1, x2 = x2, y = y)
proba <- predict(logit.reg, data, type = "response")
preds <- ifelse(proba > 0.5, 1, 0)
pred.pos <- data[preds == 1, ]
pred.neg <- data[preds == 0, ]
plot(pred.pos$x1, pred.pos$x2,
col = 'black', pch = 2,
xlab = "X1", ylab = "X2")
points(pred.neg$x1, pred.neg$x2, col = 'red', pch = 3)
#a
set.seed(10)
x1 <- runif(500) - 0.5
x2 <- runif(500) - 0.5
y <- 1 * (x1^2 - x2^2 > 0)
help(runif)
#b
plot(x1, x2, xlab = "X1", ylab = "X2",
col = y+1, pch =y+2)
#c
logit.reg <- glm(y ~ x1 + x2, family = binomial)
summary(logit.reg)
#d
data <- data.frame(x1 = x1, x2 = x2, y = y)
proba <- predict(logit.reg, data, type = "response")
preds <- ifelse(proba > 0.5, 1, 0)
pred.pos <- data[preds == 1, ]
pred.neg <- data[preds == 0, ]
plot(pred.pos$x1, pred.pos$x2,
col = 'black', pch = 2,
xlab = "X1", ylab = "X2")
points(pred.neg$x1, pred.neg$x2, col = 'red', pch = 3)
plot(x1, x2, xlab = "X1", ylab = "X2",
col = y+1, pch =y+2)
#c
logit.reg <- glm(y ~ x1 + x2, family = binomial)
summary(logit.reg)
#d
data <- data.frame(x1 = x1, x2 = x2, y = y)
proba <- predict(logit.reg, data, type = "response")
preds <- ifelse(proba > 0.5, 1, 0)
pred.pos <- data[preds == 1, ]
pred.neg <- data[preds == 0, ]
plot(pred.pos$x1, pred.pos$x2,
col = 'black', pch = 2,
xlab = "X1", ylab = "X2")
points(pred.neg$x1, pred.neg$x2, col = 'red', pch = 3)
#d
data <- data.frame(x1 = x1, x2 = x2, y = y)
proba <- predict(logit.reg, data, type = "response")
preds <- ifelse(proba > 0.5, 1, 0)
pred.pos <- data[preds == 1, ]
pred.neg <- data[preds == 0, ]
plot(pred.pos$x1, pred.pos$x2,
col = 'black', pch = 2,
xlab = "X1", ylab = "X2")
points(pred.neg$x1, pred.neg$x2, col = 'red', pch = 3)
#a
set.seed(10)
x1 <- runif(500) - 0.5
x2 <- runif(500) - 0.5
y <- 1 * (x1^2 - x2^2 > 0)
help(runif)
#b
plot(x1, x2, xlab = "X1", ylab = "X2",
col = y+1, pch =y+2)
#c
logit.reg <- glm(y ~ x1 + x2, family = binomial)
summary(logit.reg)
#d
data <- data.frame(x1 = x1, x2 = x2, y = y)
proba <- predict(logit.reg, data, type = "response")
preds <- ifelse(proba > 0.5, 1, 0)
pred.pos <- data[preds == 1, ]
pred.neg <- data[preds == 0, ]
plot(pred.pos$x1, pred.pos$x2,
col = 'black', pch = 2,
xlab = "X1", ylab = "X2")
points(pred.neg$x1, pred.neg$x2, col = 'red', pch = 3)
#a
set.seed(10)
x1 <- runif(500) - 0.5
x2 <- runif(500) - 0.5
y <- 1 * (x1^2 - x2^2 > 0)
help(runif)
#b
plot(x1, x2, xlab = "X1", ylab = "X2",
col = y+1, pch =y+2)
#c
logit.reg <- glm(y ~ x1 + x2, family = binomial)
summary(logit.reg)
#d
data <- data.frame(x1 = x1, x2 = x2, y = y)
proba <- predict(logit.reg, data, type = "response")
preds <- ifelse(proba > 0.47, 1, 0)
pred.pos <- data[preds == 1, ]
pred.neg <- data[preds == 0, ]
plot(pred.pos$x1, pred.pos$x2,
col = 'black', pch = 2,
xlab = "X1", ylab = "X2")
points(pred.neg$x1, pred.neg$x2, col = 'red', pch = 3)
set.seed(1)
x1 <- runif(500) - 0.5
x2 <- runif(500) - 0.5
y <- 1 * (x1^2 - x2^2 > 0)
plot(x1, x2, xlab = "X1", ylab = "X2", col = (4 - y), pch = (3 - y))
logit.fit <- glm(y ~ x1 + x2, family = "binomial")
summary(logit.fit)
data <- data.frame(x1 = x1, x2 = x2, y = y)
probs <- predict(logit.fit, data, type = "response")
preds <- rep(0, 500)
preds[probs > 0.47] <- 1
plot(data[preds == 1, ]$x1, data[preds == 1, ]$x2, col = (4 - 1), pch = (3 - 1), xlab = "X1", ylab = "X2")
points(data[preds == 0, ]$x1, data[preds == 0, ]$x2, col = (4 - 0), pch = (3 - 0))
data <- data.frame(x1 = x1, x2 = x2, y = y)
proba <- predict(logit.fit, data, type = "response")
preds <- ifelse(proba > 0.47, 1, 0)
pred.pos <- data[preds == 1, ]
pred.neg <- data[preds == 0, ]
plot(pred.pos$x1, pred.pos$x2,
col = 'black', pch = 2,
xlab = "X1", ylab = "X2")
points(pred.neg$x1, pred.neg$x2, col = 'red', pch = 3)
data <- data.frame(x1 = x1, x2 = x2, y = y)
proba <- predict(logit.fit, data, type = "response")
preds <- ifelse(proba > 0.5, 1, 0)
pred.pos <- data[preds == 1, ]
pred.neg <- data[preds == 0, ]
plot(pred.pos$x1, pred.pos$x2,
col = 'black', pch = 2,
xlab = "X1", ylab = "X2")
points(pred.neg$x1, pred.neg$x2, col = 'red', pch = 3)
set.seed(1)
x1 <- runif(500) - 0.5
x2 <- runif(500) - 0.5
y <- 1 * (x1^2 - x2^2 > 0)
plot(x1, x2, xlab = "X1", ylab = "X2", col = (4 - y), pch = (3 - y))
logit.fit <- glm(y ~ x1 + x2, family = "binomial")
summary(logit.fit)
data <- data.frame(x1 = x1, x2 = x2, y = y)
proba <- predict(logit.fit, data, type = "response")
preds <- ifelse(proba > 0.5, 1, 0)
pred.pos <- data[preds == 1, ]
pred.neg <- data[preds == 0, ]
plot(pred.pos$x1, pred.pos$x2,
col = 'black', pch = 2,
xlab = "X1", ylab = "X2")
points(pred.neg$x1, pred.neg$x2, col = 'red', pch = 3)
#a
set.seed(10)
x1 <- runif(500) - 0.5
x2 <- runif(500) - 0.5
y <- 1 * (x1^2 - x2^2 > 0)
help(runif)
#b
plot(x1, x2, xlab = "X1", ylab = "X2",
col = y+1, pch =y+2)
#c
logit.reg <- glm(y ~ x1 + x2, family = binomial)
summary(logit.reg)
#d
data <- data.frame(x1 = x1, x2 = x2, y = y)
proba <- predict(logit.reg, data, type = "response")
preds <- ifelse(proba > 0.47, 1, 0)
pred.pos <- data[preds == 1, ]
pred.neg <- data[preds == 0, ]
plot(pred.pos$x1, pred.pos$x2,
col = 'black', pch = 2,
xlab = "X1", ylab = "X2")
points(pred.neg$x1, pred.neg$x2, col = 'red', pch = 3)
data <- data.frame(x1 = x1, x2 = x2, y = y)
proba <- predict(logit.fit, data, type = "response")
preds <- ifelse(proba > 0.5, 1, 0)
pred.pos <- data[preds == 1, ]
pred.neg <- data[preds == 0, ]
plot(pred.pos$x1, pred.pos$x2,
col = 'black', pch = 2,
xlab = "X1", ylab = "X2")
points(pred.neg$x1, pred.neg$x2, col = 'red', pch = 3)
data <- data.frame(x1 = x1, x2 = x2, y = y)
proba <- predict(logit.fit, data, type = "response")
preds <- ifelse(proba > 0.5, 1, 0)
pred.pos <- data[preds == 1, ]
pred.neg <- data[preds == 0, ]
plot(pred.pos$x1, pred.pos$x2,
col = 'black', pch = 2,
xlab = "X1", ylab = "X2")
points(pred.neg$x1, pred.neg$x2, col = 'red', pch = 3)
data
proba
set.seed(2)
x1 <- runif(500) - 0.5
x2 <- runif(500) - 0.5
y <- 1 * (x1^2 - x2^2 > 0)
plot(x1, x2, xlab = "X1", ylab = "X2", col = (4 - y), pch = (3 - y))
logit.fit <- glm(y ~ x1 + x2, family = "binomial")
summary(logit.fit)
data <- data.frame(x1 = x1, x2 = x2, y = y)
probs <- predict(logit.fit, data, type = "response")
preds <- rep(0, 500)
preds[probs > 0.47] <- 1
plot(data[preds == 1, ]$x1, data[preds == 1, ]$x2, col = (4 - 1), pch = (3 - 1), xlab = "X1", ylab = "X2")
points(data[preds == 0, ]$x1, data[preds == 0, ]$x2, col = (4 - 0), pch = (3 - 0))
data <- data.frame(x1 = x1, x2 = x2, y = y)
proba <- predict(logit.fit, data, type = "response")
preds <- ifelse(proba > 0.5, 1, 0)
pred.pos <- data[preds == 1, ]
pred.neg <- data[preds == 0, ]
plot(pred.pos$x1, pred.pos$x2,
col = 'black', pch = 2,
xlab = "X1", ylab = "X2")
points(pred.neg$x1, pred.neg$x2, col = 'red', pch = 3)
set.seed(1)
x1 <- runif(500) - 0.5
x2 <- runif(500) - 0.5
y <- 1 * (x1^2 - x2^2 > 0)
plot(x1, x2, xlab = "X1", ylab = "X2", col = (4 - y), pch = (3 - y))
logit.fit <- glm(y ~ x1 + x2, family = "binomial")
summary(logit.fit)
data <- data.frame(x1 = x1, x2 = x2, y = y)
proba <- predict(logit.fit, data, type = "response")
preds <- ifelse(proba > 0.5, 1, 0)
pred.pos <- data[preds == 1, ]
pred.neg <- data[preds == 0, ]
plot(pred.pos$x1, pred.pos$x2,
col = 'black', pch = 2,
xlab = "X1", ylab = "X2")
points(pred.neg$x1, pred.neg$x2, col = 'red', pch = 3)
preds
proba
pred.pos
pred.neg
plot(pred.pos$x1, pred.pos$x2,
col = 'black', pch = 2,
xlab = "X1", ylab = "X2")
points(pred.neg$x1, pred.neg$x2, col = 'red', pch = 3)
#a
set.seed(10)
x1 <- runif(500) - 0.5
x2 <- runif(500) - 0.5
y <- 1 * (x1^2 - x2^2 > 0)
help(runif)
#b
plot(x1, x2, xlab = "X1", ylab = "X2",
col = y+1, pch =y+2)
#c
logit.reg <- glm(y ~ x1 + x2, family = binomial)
summary(logit.reg)
#d
data <- data.frame(x1 = x1, x2 = x2, y = y)
proba <- predict(logit.reg, data, type = "response")
preds <- ifelse(proba > 0.47, 1, 0)
pred.pos <- data[preds == 1, ]
pred.neg <- data[preds == 0, ]
plot(pred.pos$x1, pred.pos$x2,
col = 'black', pch = 2,
xlab = "X1", ylab = "X2")
points(pred.neg$x1, pred.neg$x2, col = 'red', pch = 3)
#a
set.seed(1)
x1 <- runif(500) - 0.5
x2 <- runif(500) - 0.5
y <- 1 * (x1^2 - x2^2 > 0)
help(runif)
#b
plot(x1, x2, xlab = "X1", ylab = "X2",
col = y+1, pch =y+2)
#c
logit.reg <- glm(y ~ x1 + x2, family = binomial)
summary(logit.reg)
#d
data <- data.frame(x1 = x1, x2 = x2, y = y)
proba <- predict(logit.reg, data, type = "response")
preds <- ifelse(proba > 0.47, 1, 0)
pred.pos <- data[preds == 1, ]
pred.neg <- data[preds == 0, ]
plot(pred.pos$x1, pred.pos$x2,
col = 'black', pch = 2,
xlab = "X1", ylab = "X2")
points(pred.neg$x1, pred.neg$x2, col = 'red', pch = 3)
#a
set.seed(10)
x1 <- runif(500) - 0.5
x2 <- runif(500) - 0.5
y <- 1 * (x1^2 - x2^2 > 0)
help(runif)
#b
plot(x1, x2, xlab = "X1", ylab = "X2",
col = y+1, pch =y+2)
#c
logit.reg <- glm(y ~ x1 + x2, family = binomial)
summary(logit.reg)
#d
data <- data.frame(x1 = x1, x2 = x2, y = y)
proba <- predict(logit.reg, data, type = "response")
preds <- ifelse(proba > 0.47, 1, 0)
pred.pos <- data[preds == 1, ]
pred.neg <- data[preds == 0, ]
plot(pred.pos$x1, pred.pos$x2,
col = 'black', pch = 2,
xlab = "X1", ylab = "X2")
points(pred.neg$x1, pred.neg$x2, col = 'red', pch = 3)
setwd("~/Desktop/Resume/19Summer Intern/上海宽投资产/附件-数据分析题03_销售数据分析")
read.csv('附件4-商品信息表.csv')
